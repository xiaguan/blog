---
import Layout from '../layouts/BlogPost.astro';
---

<Layout
	title="About Me"
	description="About Jinyang Su (susun) — LLM inference engineer and former database storage engineer."
	pubDate={new Date('February 22 2026')}
>
	<p>
		Hi there! I'm <strong>Jinyang Su</strong>, also known as <strong>susun</strong> online.
		I'm a systems engineer working on LLM inference and infrastructure.
	</p>

	<h3>what i do now</h3>
	<p>
		I work as an <strong>LLM inference engineer</strong>, building production serving infrastructure.
		My main project is <a href="https://github.com/novitalabs/pegaflow" target="_blank">Pegaflow</a>
		— a distributed KV cache system with RDMA support for LLM inference. The daily work is a mix of
		storage architecture, networking, and GPU-side optimization — figuring out how to move data
		as fast as possible so models can serve at scale.
	</p>
	<p>
		On the side, I'm building <a href="https://github.com/xiaguan/pegainfer" target="_blank">pegainfer</a>
		— a from-scratch LLM inference engine written in Rust with hand-written CUDA kernels.
	</p>

	<h3>where i come from</h3>
	<p>
		Before LLM inference, I was a <strong>database storage engineer</strong>. I worked on storage engines,
		write-ahead logs, compaction strategies, and all the low-level plumbing that makes databases reliable.
		That background turns out to be surprisingly relevant — distributed caching, eviction algorithms,
		async I/O, and memory management are just as central to inference serving as they are to databases.
	</p>

	<h3>what i think about</h3>
	<p>
		I care about <strong>controlling complexity</strong>. The essence of programming is managing complexity,
		and I've learned (sometimes the hard way) that understanding must come before delegation — whether
		to a teammate or an AI coding agent. I use OKRs to keep myself focused on what matters, and I try
		to remind myself: if everything is equally important, nothing is.
	</p>

	<h3>this blog</h3>
	<p>
		Writing forces clarity. This blog is where I write about systems engineering, inference optimization,
		RDMA, storage internals, and lessons from building production systems. I write primarily for my
		future self — to solidify understanding and document the journey. If others find it useful, that's a bonus.
	</p>

	<h3>get in touch</h3>
	<p>
		You can find my work on <a href="https://github.com/xiaguan" target="_blank">GitHub</a>.
		Feel free to reach out if you want to chat about systems, inference, or anything in between.
	</p>
</Layout>
